{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from lxml import html\n",
    "\n",
    "from datetime import datetime as dt, timedelta as td\n",
    "import locale\n",
    "locale.setlocale(locale.LC_ALL, 'ru_RU')\n",
    "\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import Column, String\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    \n",
    "    def __init__(self, url):\n",
    "        self.main_link = url\n",
    "        self.headers = {'User-agent': 'Mozilla/5.0'}\n",
    "        response = requests.get(url, headers=self.headers)\n",
    "        self.root = html.fromstring(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Yandex(Parser):\n",
    "    \n",
    "    def parser(self):\n",
    "        \n",
    "        titles = iter(self.root.xpath('//h2[@class=\"story__title\"]/a/text()'))\n",
    "        \n",
    "        links = (l.split('?')[0] if l.startswith('https')\n",
    "                 else 'https://yandex.ru' + l.split('?')[0] for l\n",
    "                 in self.root.xpath('//h2[@class=\"story__title\"]/a/@href'))\n",
    "\n",
    "        sources = (' '.join(s.split()[:-1]) if 'вчера' not in s else\n",
    "                   ' '.join(s.split()[:-3]) for s\n",
    "                   in self.root.xpath('//div[@class=\"story__date\"]/text()'))\n",
    "\n",
    "        dates = (str(dt.now().date()) + ' ' + d[-5:] if 'вчера' not in d else\n",
    "                 str((dt.now() - td(days=1)).date()) + ' ' + d[-5:] for d\n",
    "                 in self.root.xpath('//div[@class=\"story__date\"]/text()'))\n",
    "        \n",
    "        return zipper(zip(titles, links, dates), source=sources)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lenta(Parser):\n",
    "\n",
    "    def get_head(self):\n",
    "        return [{\n",
    "            'title': self.root.xpath('//div[@class=\"first-item\"]/h2/a/text()')[0].replace('\\xa0', ' '),\n",
    "            'url': self.main_link + self.root.xpath('//div[@class=\"first-item\"]/h2/a/@href')[0],\n",
    "            'source': 'Lenta.ru',\n",
    "            'date': str(dt.strptime(\n",
    "                self.root.xpath('//div[@class=\"first-item\"]/h2/a/time/@datetime')[0],\n",
    "                ' %H:%M,  %d %B %Y'))[:-3]\n",
    "        }]\n",
    "\n",
    "    def get_body(self):\n",
    "\n",
    "        body_zip = zip(\n",
    "            (t.replace('\\xa0', ' ') for t in self.root.xpath('//div[@class=\"item\"]/a/text()')),\n",
    "            (self.main_link + l for l in self.root.xpath('//div[@class=\"item\"]/a/@href')),\n",
    "            (str(dt.strptime(t, ' %H:%M,  %d %B %Y'))[:-3] for t\n",
    "             in self.root.xpath('//div[@class=\"item\"]/a/time/@datetime'))\n",
    "        )\n",
    "        return zipper(body_zip, source='Lenta.ru')\n",
    "\n",
    "    def get_footer(self):\n",
    "\n",
    "        footer_zip = zip(\n",
    "            (t.replace('\\xa0', ' ') for t in self.root.xpath('//div[@class=\"titles\"]/h3/a/span/text()')),\n",
    "            (self.main_link + t for t in self.root.xpath('//div[@class=\"titles\"]/h3/a/@href') if 'https' not in t),\n",
    "            (' '.join(date_tuple) for date_tuple in zip(\n",
    "                (str(dt.now().date()) if d == 'Сегодня'\n",
    "                 else str((dt.strptime(d, ' %d %B') + td(days=365 * 120 + 30)).date())\n",
    "                 for d in self.root.xpath('//span[@class=\"g-date item__date\"]/text()')),\n",
    "                self.root.xpath('//span[@class=\"time\"]/text()'))),\n",
    "        )\n",
    "        return zipper(footer_zip, source='Lenta.ru')\n",
    "\n",
    "    def parser(self):\n",
    "        head = self.get_head()\n",
    "        body = self.get_body()\n",
    "        footer = self.get_footer()\n",
    "        return head + body + footer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mail(Parser):\n",
    "\n",
    "    def dive_into(self, links):\n",
    "        roots = [html.fromstring(requests.get(link, headers=self.headers).text) for link in links]\n",
    "        dates = (r.xpath('//span[@class=\"note\"]/span/@datetime')[0][:-9].replace('T', ' ') for r in roots)\n",
    "        sources = (r.xpath('//span/span/a/span[@class=\"link__text\"]/text()')[0] for r in roots)\n",
    "        return dates, sources\n",
    "\n",
    "    def get_head(self):\n",
    "        titles = (t.replace('\\xa0', ' ') for t in self.root.xpath('//span[@class=\"photo__captions\"]/span[1]/text()'))\n",
    "        links = [self.main_link + l if 'https' not in l else l \n",
    "                 for l in self.root.xpath('//div[@class=\"photo__inner\"]/../@href')[:5]]\n",
    "        dates, sources = self.dive_into(links)\n",
    "        return zipper(zip(titles, links, dates), source=sources)\n",
    "\n",
    "    def get_body(self):\n",
    "        titles_upper = self.root.xpath('//div[@class=\"cols__inner\"]/div/span/a/span/text()')\n",
    "        titles_lower = self.root.xpath('//span[@class=\"list__text\"]/a/span/text()')\n",
    "        titles = [t.replace('\\xa0', ' ') for t in titles_upper + titles_lower]\n",
    "        \n",
    "        links_upper = self.root.xpath('//a[@class=\"newsitem__title link-holder\"]/@href')\n",
    "        links_lower = self.root.xpath('//span[@class=\"list__text\"]/a/@href')\n",
    "        links = [self.main_link + l for l in links_upper + links_lower]\n",
    "        \n",
    "        dates, sources = self.dive_into(links)\n",
    "        return zipper(zip(titles, links, dates), source=sources)\n",
    "\n",
    "    def parser(self):\n",
    "        head = self.get_head()\n",
    "        body = self.get_body()\n",
    "        return head + body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zipper(columns, source):\n",
    "    return [{\n",
    "        'title': unit[0],\n",
    "        'url': unit[1],\n",
    "        'source': source if type(source) == str else next(source),\n",
    "        'date': unit[2]} for unit in columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Connector:\n",
    "\n",
    "    def __init__(self):\n",
    "        db_string = \"postgres://localhost:5432/vacancies\"\n",
    "        self.db = create_engine(db_string)\n",
    "        base = declarative_base()\n",
    "\n",
    "        class Vacancy(base):\n",
    "            __tablename__ = 'vacancies_table'\n",
    "            title = Column(String, primary_key=True)\n",
    "            url = Column(String)\n",
    "            source = Column(String)\n",
    "            date = Column(String)\n",
    "\n",
    "        self.table = Vacancy\n",
    "        session = sessionmaker(self.db)\n",
    "        self.session = session()\n",
    "        base.metadata.create_all(self.db)\n",
    "\n",
    "    def insert(self, news):\n",
    "        i = 0\n",
    "        for item in news:\n",
    "            duple = self.session.query(self.table).get(item['title'])\n",
    "            if not duple:\n",
    "                vacancy_item = self.table(\n",
    "                    title=item['title'],\n",
    "                    url=item['url'],\n",
    "                    source=item['source'],\n",
    "                    date=item['date'])\n",
    "\n",
    "                self.session.add(vacancy_item)\n",
    "                i += 1\n",
    "            else:\n",
    "                print(f'\"{duple.title}\" already exists, pass\\n')\n",
    "                \n",
    "        self.session.commit()\n",
    "        print(f'{i} items added')\n",
    "        print(f'{self.session.query(self.table).count()} items total')\n",
    "\n",
    "    def head(self, num):\n",
    "        vacancies = self.session.query(self.table).limit(num)\n",
    "        for v in vacancies:\n",
    "            print(f'Title: {v.title}')\n",
    "            print(f'Date: {v.date}')\n",
    "            print(f'Source: {v.source}')\n",
    "            print(f'Url: {v.url}')\n",
    "            print()\n",
    "\n",
    "    def clear(self):\n",
    "        self.table.__table__.drop(self.db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector = Connector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 items added\n",
      "65 items total\n"
     ]
    }
   ],
   "source": [
    "yandex = Yandex(url='https://yandex.ru/news')\n",
    "news = yandex.parser()\n",
    "\n",
    "connector.insert(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Российский «Лидер» оказался аутсайдером\" already exists, pass\n",
      "\n",
      "\"Названы вакансии с зарплатой 800 тысяч рублей\" already exists, pass\n",
      "\n",
      "79 items added\n",
      "144 items total\n"
     ]
    }
   ],
   "source": [
    "lenta = Lenta(url='https://lenta.ru')\n",
    "news = lenta.parser()\n",
    "\n",
    "connector.insert(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Пилот Коби Брайанта был в секундах от спасения вертолета\" already exists, pass\n",
      "\n",
      "26 items added\n",
      "170 items total\n"
     ]
    }
   ],
   "source": [
    "mail = Mail(url='https://news.mail.ru')\n",
    "news = mail.parser()\n",
    "\n",
    "connector.insert(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: В Казахстане восемь человек погибли в массовой драке\n",
      "Date: 2020-02-08 18:04\n",
      "Source: РИА Новости\n",
      "Url: https://yandex.ru/news/story/V_Kazakhstane_vosem_chelovek_pogibli_v_massovoj_drake--e2a63ed10fcce2c9c7dda20585b3ccc7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "connector.head(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
